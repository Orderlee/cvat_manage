import os
import csv
import requests
import subprocess
import zipfile
from datetime import datetime
from dotenv import load_dotenv
from pathlib import Path

# === í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ===
env_path = Path(__file__).resolve().parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

CVAT_URL = os.getenv("CVAT_URL_2")
TOKEN = os.getenv("TOKEN_2")
CVAT_USERNAME = os.getenv("CVAT_USERNAME")
CVAT_PASSWORD = os.getenv("CVAT_PASSWORD")
CVAT_EXPORT_FORMAT = os.getenv("CVAT_EXPORT_FORMAT")
CVAT_EXPORT_FORMAT_4 = os.getenv("CVAT_EXPORT_FORMAT_4")  # skeleton ìš© í¬ë§·
WITH_IMAGES = os.getenv("WITH_IMAGES")
# ì£¼ì˜: ì‚¬ìš©ìê°€ ì œê³µí•œ í‚¤ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
ORGANIZATIONS = [org.strip() for org in os.getenv("ORGANIZATIONS", "").split(",")]  
RESULT_DIR = os.getenv("RESULT_DIR", "/tmp/cvat_exports")

HEADERS = {
    "Authorization": f"Token {TOKEN}",
    "Content-Type": "application/json"
}

# === íŠ¹ì • í”„ë¡œì íŠ¸ ê°•ì œ export ëª¨ë“œ íŠ¸ë¦¬ê±° ===
# ì•„ë˜ ë¬¸ìì—´ì´ task_name / project_name / org_slug ì¤‘ í•˜ë‚˜ì— (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ) í¬í•¨ë˜ë©´
# export_log.csv ì¤‘ë³µ ì²´í¬ë¥¼ ë¬´ì‹œí•˜ê³  ê°•ì œ export ìˆ˜í–‰
PROJECT_NAME = ""   # ë¹„í™œì„±í™”í•˜ë ¤ë©´ "" ë¡œ ë‘ì„¸ìš”.

# === JSONë§Œ í¬í•¨ëœ zipìœ¼ë¡œ ë®ì–´ì“°ê¸° ===
def extract_json_and_only_json(zip_path: Path):
    with zipfile.ZipFile(zip_path, "r") as zip_ref:
        json_files = [f for f in zip_ref.namelist() if f.endswith(".json") and f.startswith("annotations/")]
        if not json_files:
            print(f"âš ï¸ JSON íŒŒì¼ ì—†ìŒ: {zip_path}")
            return
        json_internal_path = json_files[0]
        json_data = zip_ref.read(json_internal_path)
        json_filename = zip_path.stem + ".json"

    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as new_zip:
        new_zip.writestr(json_filename, json_data)

    print(f"ğŸ“¦ JSONë§Œ í¬í•¨ëœ zipìœ¼ë¡œ ë®ì–´ì“°ê¸° ì™„ë£Œ: {zip_path.name}")

# === ìœ í‹¸ í•¨ìˆ˜ ===
def get_all_jobs():
    jobs = []
    page = 1
    while True:
        r = requests.get(f"{CVAT_URL}/api/jobs?page={page}", headers=HEADERS)
        r.raise_for_status()
        data = r.json()
        jobs.extend(data["results"])
        if not data["next"]:
            break
        page += 1
    return jobs

def get_task_info(task_id: int):
    r = requests.get(f"{CVAT_URL}/api/tasks/{task_id}", headers=HEADERS)
    r.raise_for_status()
    return r.json()

def get_project_name(project_id: int | None) -> str:
    if not project_id:
        return ""
    r = requests.get(f"{CVAT_URL}/api/projects/{project_id}", headers=HEADERS)
    if r.status_code == 404:
        return ""
    r.raise_for_status()
    data = r.json()
    # CVAT ë²„ì „ì— ë”°ë¼ name/title í•„ë“œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ë„‰ë„‰í•˜ê²Œ ì²˜ë¦¬
    return data.get("name") or data.get("title") or ""

def get_annotations(job_id):
    r = requests.get(f"{CVAT_URL}/api/jobs/{job_id}/annotations", headers=HEADERS)
    r.raise_for_status()
    return r.json()

def get_organization_name(org_id):
    if not org_id:
        return ""
    r = requests.get(f"{CVAT_URL}/api/organizations/{org_id}", headers=HEADERS)
    if r.status_code == 404:
        return ""
    r.raise_for_status()
    return r.json().get("slug", "")  # slug ê¸°ì¤€ í•„í„°

def load_assignee_map_from_env():
    assignee_map = {}
    for key, value in os.environ.items():
        if key.startswith("USERMAP_"):
            username = key.replace("USERMAP_", "")
            assignee_map[username] = value
    return assignee_map

def get_label_types_from_annotations(job_id):
    label_types = set()
    try:
        annotations = get_annotations(job_id)
        for shape in annotations.get("shapes", []):
            shape_type = shape.get("shape_type") or shape.get("type")
            if shape_type:
                label_types.add(shape_type)
    except requests.RequestException as e:
        print(f"âš ï¸ ì–´ë…¸í…Œì´ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (job_id={job_id}): {e}")
        return set()
    print(f"ğŸ“Œ Job ID {job_id} â†’ ì‚¬ìš©ëœ ë¼ë²¨ íƒ€ì…: {label_types}")
    return label_types

def run_cvat_cli_export(task_id: int, task_name: str, assignee: str, result_dir: Path,
                        export_log_path: Path, assignee_map: dict, export_format: str,
                        log_name_override: str | None = None):
    safe_name = task_name
    exported_date = datetime.today().strftime("%Y-%m-%d")

    # export_format ê°’ì— ë”°ë¼ íŒŒì¼ëª… ì ‘ë¯¸ì‚¬ ê²°ì •
    if export_format == CVAT_EXPORT_FORMAT:
        suffix = "_boundingbox"
    elif export_format == CVAT_EXPORT_FORMAT_4:
        suffix = "_keypoint"
    else:
        suffix = ""
    output_path = result_dir / f"{safe_name}{suffix}.zip"

    command = (
        f'cvat-cli --server-host {CVAT_URL} '
        f'--auth {CVAT_USERNAME}:{CVAT_PASSWORD} '
        f'task export-dataset {task_id} "{output_path}" '
        f'--format "{export_format}" '
        f'--with-images {WITH_IMAGES}'
    )
    try:
        print(f"ğŸš€ Exporting: Task {task_id} â†’ {output_path.name}")
        subprocess.run(command, shell=True, check=True)
        print(f"âœ… Export ì„±ê³µ â†’ {output_path}")

        mapped_assignee = assignee_map.get(assignee, assignee)
        log_name = log_name_override if log_name_override else task_name

        with open(export_log_path, "a", newline='') as f:
            writer = csv.writer(f)
            writer.writerow([task_id, log_name, mapped_assignee, exported_date])

        extract_json_and_only_json(output_path)

    except subprocess.CalledProcessError as e:
        print(f"âŒ Export ì‹¤íŒ¨: Task {task_id} - {e}")

def ci_contains(needle: str, hay: str) -> bool:
    return needle.lower() in hay.lower()

# === ë©”ì¸ ===
def main():
    jobs = get_all_jobs()
    today_str = datetime.today().strftime("%Y-%m-%d")
    base_result_dir = Path(RESULT_DIR)

    export_log_path = Path("/home/pia/work_p/dfn/omission/result/export_log.csv")
    if not export_log_path.exists():
        with open(export_log_path, "w", newline='') as f:
            writer = csv.writer(f)
            writer.writerow(["task_id", "task_name", "assignee", "exported_date"])

    # ë¡œê·¸ ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€ìš© ì§‘í•©
    exported_task_ids = set()
    with open(export_log_path, "r", newline='') as f:
        reader = csv.DictReader(f)
        for row in reader:
            exported_task_ids.add(row["task_id"])

    assignee_map = load_assignee_map_from_env()
    pn = (PROJECT_NAME or "").strip()

    for job in jobs:
        task_id = str(job["task_id"])
        state = job.get("state")
        stage = job.get("stage")

        # ì™„ë£Œ + ê²€ìˆ˜í†µê³¼ë§Œ ëŒ€ìƒìœ¼ë¡œ í•„í„°
        if not (stage == "acceptance" and state == "completed"):
            continue

        task_info = get_task_info(int(task_id))
        task_name = task_info.get("name", f"task_{task_id}")
        org_slug = get_organization_name(task_info.get("organization"))
        project_name = get_project_name(task_info.get("project_id") or task_info.get("project"))

        # ì¡°ì§ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í•„í„° (í™˜ê²½ë³€ìˆ˜ ë¹„ì–´ìˆì„ ê²½ìš° ì „ì²´ í—ˆìš©)
        if ORGANIZATIONS and any(ORGANIZATIONS):
            if org_slug not in ORGANIZATIONS:
                continue

        assignee_info = job.get("assignee")
        assignee = assignee_info.get("username", "(unassigned)") if assignee_info else "(unassigned)"
        label_types = get_label_types_from_annotations(int(job["id"]))

        result_dir = base_result_dir / today_str / (org_slug or "no_org") / task_name
        result_dir.mkdir(parents=True, exist_ok=True)

        # === ìë™ ë¬´ì‹œ ëª¨ë“œ íŒë‹¨ (task_name / project_name / org_slug ëª¨ë‘ ê²€ì‚¬)
        ignore_mode = False
        matched_field = ""
        if pn:
            if ci_contains(pn, task_name):
                ignore_mode, matched_field = True, "task_name"
            elif project_name and ci_contains(pn, project_name):
                ignore_mode, matched_field = True, "project_name"
            elif org_slug and ci_contains(pn, org_slug):
                ignore_mode, matched_field = True, "org_slug"

        if ignore_mode:
            print(f"âš¡ [ë¬´ì‹œ ëª¨ë“œ] '{PROJECT_NAME}' ë§¤ì¹­({matched_field}) â†’ export_log.csv ë¬´ì‹œí•˜ê³  ê°•ì œ export: task={task_name}, project={project_name}, org={org_slug}")
        else:
            # === ì¼ë°˜ ëª¨ë“œ: export_log.csv ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€ ===
            if task_id in exported_task_ids:
                print(f"â© ì´ë¯¸ exportë¨ â†’ Task {task_id}, ê±´ë„ˆëœ€")
                continue

        # === ì‹¤ì œ export ì‹¤í–‰ ===
        if label_types == {"rectangle"}:
            run_cvat_cli_export(int(task_id), task_name, assignee, result_dir, export_log_path,
                                assignee_map, CVAT_EXPORT_FORMAT)
        elif label_types == {"skeleton"}:
            run_cvat_cli_export(int(task_id), task_name, assignee, result_dir, export_log_path,
                                assignee_map, CVAT_EXPORT_FORMAT_4, log_name_override=task_name + "_k")
        elif {"rectangle", "skeleton"}.issubset(label_types):
            # ë‘˜ ë‹¤ ìˆìœ¼ë©´ ë‘ ë²ˆ export
            run_cvat_cli_export(int(task_id), task_name, assignee, result_dir, export_log_path,
                                assignee_map, CVAT_EXPORT_FORMAT, log_name_override=task_name)
            run_cvat_cli_export(int(task_id), task_name, assignee, result_dir, export_log_path,
                                assignee_map, CVAT_EXPORT_FORMAT_4, log_name_override=task_name + "_k")

if __name__ == "__main__":
    main()
