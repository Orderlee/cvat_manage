# import os
# import cv2
# import csv
# import time
# from pathlib import Path
# from collections import defaultdict, deque
# from datetime import datetime
# from multiprocessing import Pool, get_start_method, set_start_method, Manager
# import threading

# from tqdm import tqdm
# from dotenv import load_dotenv

# """
# ê³ ê¸‰ ìŠ¤ì¼€ì¤„ëŸ¬ (ì„¸ë§ˆí¬ì–´ ê¸°ë°˜, Manager.Value ì ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìš”êµ¬ì‚¬í•­ ë°˜ì˜:
# - YOLOë¡œ ì‚¬ëŒì„ ì°¾ì•„, 'ì‚¬ëŒì´ ê°€ì¥ ë§ì´ íƒì§€ëœ ì—°ì† 15ë¶„' êµ¬ê°„ë§Œ ê³¨ë¼ì„œ
#   í•´ë‹¹ êµ¬ê°„ì—ì„œ '2ì´ˆë‹¹ 1í”„ë ˆì„(0.5fps)'ë¡œ ì´ë¯¸ì§€ ì¶”ì¶œ
# - ê¸°ì¡´ ë©€í‹°-GPU ìŠ¤ì¼€ì¤„ëŸ¬/ì„¸ë§ˆí¬ì–´/ë¡œê·¸ êµ¬ì¡°ëŠ” ìœ ì§€

# êµ¬í˜„ ê°œìš”:
# - detect_and_extract_worker:
#   1) 1ì°¨ íŒ¨ìŠ¤(ìƒ˜í”Œë§ íƒì§€): sampling_rate ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ì„ í›‘ìœ¼ë©° ì´ˆ ë‹¨ìœ„ë¡œ person ì¹´ìš´íŠ¸ë¥¼ ëˆ„ì 
#   2) 15ë¶„(900ì´ˆ) ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ìµœë‹¤ íƒì§€ êµ¬ê°„ ê³„ì‚°
#   3) 2ì°¨ íŒ¨ìŠ¤: í•´ë‹¹ êµ¬ê°„ì—ì„œë§Œ 2ì´ˆë‹¹ 1í”„ë ˆì„ìœ¼ë¡œ ì €ì¥
# """

# # =============================
# # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.envëŠ” ìƒìœ„ í´ë”ì— ìˆë‹¤ê³  ê°€ì •)
# # =============================
# env_path = Path(__file__).resolve().parent.parent / ".env"
# load_dotenv(dotenv_path=env_path)

# # ê³µí†µ ê²½ë¡œ/ì„¤ì •
# INPUT_ROOT = os.getenv("INPUT_ROOT")
# OUTPUT_ROOT = os.getenv("OUTPUT_ROOT")
# ASSIGN_LOG_DIR = os.getenv("ASSIGN_LOG_DIR", ".")
# os.makedirs(ASSIGN_LOG_DIR, exist_ok=True)
# PROCESSED_LOG = os.path.join(ASSIGN_LOG_DIR, "processed_videos.csv")
# SUMMARY_LOG = os.path.join(ASSIGN_LOG_DIR, "frame_summary_log.csv")

# # ëª¨ë“œ ì „í™˜
# PERSON_ONLY = os.getenv("PERSON_ONLY", "0") in ("1", "true", "True")
# UNIFORM_FRAMES_PER_SEC = float(os.getenv("UNIFORM_FRAMES_PER_SEC", "3"))

# # ì‚¬ëŒ ê°ì§€(ì„¸ê·¸ë¨¼íŠ¸/ë³‘ë ¬) ì„¤ì •
# PERSON_SEGMENTS = int(os.getenv("PERSON_SEGMENTS", "4"))             # ë¹„ë””ì˜¤ë¥¼ Në“±ë¶„
# WORKERS_PER_GPU = int(os.getenv("WORKERS_PER_GPU", str(PERSON_SEGMENTS)))  # GPUë‹¹ ë™ì‹œ í”„ë¡œì„¸ìŠ¤ ìˆ˜
# PERSON_SAMPLING_RATE = int(os.getenv("PERSON_SAMPLING_RATE", "5"))    # 1ì°¨ íŒ¨ìŠ¤: ní”„ë ˆì„ë§ˆë‹¤ íƒì§€
# YOLO_WEIGHTS = os.getenv("YOLO_WEIGHTS", "yolov8n.pt")
# PERSON_CONF = float(os.getenv("PERSON_CONF", "0.25"))

# # ë©€í‹°-GPU: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ GPU ID ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: "0,1")
# GPU_IDS_ENV = os.getenv("GPU_IDS", "0,1")   # ê¸°ë³¸ê°’: 2ê°œ GPU ìˆë‹¤ê³  ê°€ì •

# # ì œì™¸ ì¹´í…Œê³ ë¦¬(ì½¤ë§ˆ êµ¬ë¶„)
# EXCLUDED_CATEGORIES = set(
#     x.strip() for x in os.getenv("EXCLUDED_CATEGORIES", "").split(",") if x.strip()
# )

# # [ì‹ ê·œ] 15ë¶„ íƒ€ê²Ÿ êµ¬ê°„(ì´ˆ)
# TARGET_WINDOW_SEC = int(os.getenv("TARGET_WINDOW_SEC", str(15 * 60)))
# # [ê³ ì •] 2ì´ˆë‹¹ 1í”„ë ˆì„ ì €ì¥
# EXTRACT_EVERY_SEC = 2.0

# # =============================
# # YOLO / torch ì„í¬íŠ¸ (ì‚¬ëŒ ê°ì§€ ëª¨ë“œì—ì„œ ì‚¬ìš©)
# # =============================
# _YOLO_AVAILABLE = True
# try:
#     import torch
#     from ultralytics import YOLO
# except Exception as e:
#     _YOLO_AVAILABLE = False
#     _YOLO_IMPORT_ERROR = e


# # =============================
# # ìœ í‹¸ í•¨ìˆ˜ë“¤ (ê· ì¼ê°„ê²© ëª¨ë“œ ìœ ì§€)
# # =============================
# def get_frames_to_extract(duration_sec, fps, frames_per_sec=3):
#     if fps <= 0 or duration_sec <= 0:
#         return 0, 0
#     num_frames = int(duration_sec * frames_per_sec)
#     interval = int(fps / frames_per_sec)
#     if interval < 1:
#         interval = 1
#         num_frames = int(duration_sec * fps)
#     return num_frames, interval


# def extract_frames_uniform(video_path, save_dir, num_frames, interval_frames):
#     cap = cv2.VideoCapture(video_path)
#     total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

#     if num_frames == 0 or total_video_frames < interval_frames:
#         print(f"âš ï¸ {os.path.basename(video_path)}: ì¶”ì¶œ í”„ë ˆì„ ì—†ìŒ/ê°„ê²© ê³¼ëŒ€. ìŠ¤í‚µ")
#         cap.release()
#         return 0

#     base_name = os.path.splitext(os.path.basename(video_path))[0]
#     os.makedirs(save_dir, exist_ok=True)

#     count = 0
#     for i in range(num_frames):
#         frame_idx = i * interval_frames
#         if frame_idx >= total_video_frames:
#             break
#         cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
#         ret, frame = cap.read()
#         if ret:
#             save_path = os.path.join(save_dir, f"{base_name}_frame{i:06d}.jpg")
#             cv2.imwrite(save_path, frame)
#             count += 1
#     cap.release()
#     return count


# def is_processed(log_file, root_category, sub_category, video_file):
#     if not os.path.exists(log_file):
#         return False
#     with open(log_file, 'r') as f:
#         reader = csv.DictReader(f)
#         return any(
#             row['root_category'] == root_category and
#             row['sub_category'] == sub_category and
#             row['filename'] == video_file
#             for row in reader
#         )


# def mark_as_processed(log_file, root_category, sub_category, video_file):
#     file_exists = os.path.exists(log_file)
#     with open(log_file, 'a', newline='') as f:
#         fieldnames = ['root_category', 'sub_category', 'filename']
#         writer = csv.DictWriter(f, fieldnames=fieldnames)
#         if not file_exists:
#             writer.writeheader()
#         writer.writerow({
#             'root_category': root_category,
#             'sub_category': sub_category,
#             'filename': video_file
#         })


# # =============================
# # [í•µì‹¬] ì‚¬ëŒ ê°ì§€ìš© ì›Œì»¤ (ì—…ë°ì´íŠ¸ ë²„ì „)
# # =============================
# def detect_and_extract_worker(args):
#     """
#     args: (start_idx, end_idx, device_id, video_path, fps, sampling_rate, output_root, category)
#     ë™ì‘:
#       1) [start_idx, end_idx) ë²”ìœ„ë¥¼ 1ì°¨ íŒ¨ìŠ¤ë¡œ í›‘ìœ¼ë©° PERSON ì¡´ì¬ ì—¬ë¶€ë¥¼ 'ì´ˆ ë‹¨ìœ„' ì¹´ìš´íŠ¸ì— ëˆ„ì 
#       2) í•´ë‹¹ ë²”ìœ„ ë‚´ì—ì„œ 'ì—°ì† 15ë¶„(900ì´ˆ)' ìœˆë„ìš° ì¤‘ í•©ê³„ê°€ ìµœëŒ€ì¸ êµ¬ê°„ ì°¾ê¸°
#       3) ê·¸ êµ¬ê°„ì—ì„œë§Œ 2ì´ˆë‹¹ 1í”„ë ˆì„ìœ¼ë¡œ ì´ë¯¸ì§€ ì €ì¥
#     ë°˜í™˜: (saved_count, save_dir)
#     """
#     start_idx, end_idx, device_id, video_path, fps, sampling_rate, output_root, category = args

#     if not _YOLO_AVAILABLE:
#         raise RuntimeError(
#             f"ultralytics/torch ì„í¬íŠ¸ ì‹¤íŒ¨: {_YOLO_IMPORT_ERROR}\n"
#             f"ì‚¬ëŒ ê°ì§€ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `pip install ultralytics torch`ë¥¼ ë¨¼ì € ì„¤ì¹˜í•˜ì„¸ìš”."
#         )

#     # ë””ë°”ì´ìŠ¤ ì„¤ì •
#     use_cuda = False
#     if 'torch' in globals():
#         use_cuda = torch.cuda.is_available() and device_id is not None and device_id >= 0
#         if use_cuda:
#             torch.cuda.set_device(device_id)

#     # ëª¨ë¸ ë¡œë“œ (ê° í”„ë¡œì„¸ìŠ¤ ë³„ 1íšŒ)
#     yolo = YOLO(YOLO_WEIGHTS)

#     # ë¹„ë””ì˜¤ ì¤€ë¹„
#     cap = cv2.VideoCapture(video_path)
#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     fps = fps or cap.get(cv2.CAP_PROP_FPS) or 0.0

#     # ì¶œë ¥ í´ë”
#     video_filename = os.path.splitext(os.path.basename(video_path))[0]
#     save_dir = os.path.join(output_root, category, video_filename)
#     os.makedirs(save_dir, exist_ok=True)

#     # ê²½ê³„ ë³´ì •
#     start_idx = max(0, start_idx)
#     end_idx = min(end_idx, total_frames) if end_idx > 0 else total_frames
#     if fps <= 0 or start_idx >= end_idx:
#         cap.release()
#         return 0, save_dir

#     # ---------------------------
#     # 1) 1ì°¨ íŒ¨ìŠ¤: ìƒ˜í”Œë§ íƒì§€ â†’ ì´ˆ ë‹¨ìœ„ ì¹´ìš´íŠ¸
#     # ---------------------------
#     # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ 'ì´ˆ -> ì¹´ìš´íŠ¸'ë§Œ ì €ì¥
#     # ì´ˆ ê³„ì‚°: second = int(frame_idx / fps)
#     person_count_by_sec = defaultdict(int)

#     # 1ì°¨ íŒ¨ìŠ¤ ì§„í–‰ ë°”
#     with tqdm(total=(end_idx - start_idx), desc=f"[PASS1] {video_filename} [{start_idx}-{end_idx}) GPU:{device_id}") as pbar:
#         frame_idx = start_idx
#         cap.set(cv2.CAP_PROP_POS_FRAMES, start_idx)

#         while frame_idx < end_idx:
#             ret, frame = cap.read()
#             if not ret:
#                 break

#             # ìƒ˜í”Œë§ ìŠ¤í‚µ (ì†ë„)
#             if sampling_rate > 1 and (frame_idx % sampling_rate != 0):
#                 frame_idx += 1
#                 pbar.update(1)
#                 continue

#             # YOLO ì¶”ë¡  (conf ì§€ì •) â€” ê²°ê³¼ê°€ ë¹„ì–´ë„ names/boxes ì ‘ê·¼ ì•ˆì „
#             results = yolo(frame, verbose=False, conf=PERSON_CONF)[0]
#             has_person = False
#             if results.boxes is not None and len(results.boxes.cls) > 0:
#                 for cls_idx in results.boxes.cls.tolist():
#                     # ì•ˆì „ ì²˜ë¦¬: names ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼
#                     name = results.names.get(int(cls_idx), "")
#                     if name == "person":
#                         has_person = True
#                         break

#             if has_person:
#                 sec = int(frame_idx / fps)
#                 person_count_by_sec[sec] += 1

#             frame_idx += 1
#             pbar.update(1)

#     # ---------------------------
#     # 2) ìµœì  15ë¶„(900ì´ˆ) ì—°ì† êµ¬ê°„ ê³„ì‚° (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
#     # ---------------------------
#     total_secs = int((end_idx - start_idx) / fps) + 1
#     if total_secs <= 0:
#         cap.release()
#         return 0, save_dir

#     window_len = min(TARGET_WINDOW_SEC, total_secs)  # ì˜ìƒì´ 15ë¶„ë³´ë‹¤ ì§§ìœ¼ë©´ ì˜ìƒ ê¸¸ì´ë¡œ
#     # ì´ˆë³„ ì¹´ìš´íŠ¸ë¥¼ ë°°ì—´ë¡œ ë³€í™˜ (start_sec=0 ê¸°ì¤€)
#     sec_counts = [0] * total_secs
#     for s, c in person_count_by_sec.items():
#         local_s = s - int(start_idx / fps)
#         if 0 <= local_s < total_secs:
#             sec_counts[local_s] += c

#     # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ìµœëŒ€ í•© ì°¾ê¸° (prefix sum)
#     prefix = [0]
#     for v in sec_counts:
#         prefix.append(prefix[-1] + v)

#     best_sum = -1
#     best_start_sec_local = 0
#     for i in range(0, total_secs - window_len + 1):
#         j = i + window_len
#         ssum = prefix[j] - prefix[i]
#         if ssum > best_sum:
#             best_sum = ssum
#             best_start_sec_local = i

#     # ë¡œì»¬ êµ¬ê°„(ì‹œì‘ì´ˆ) â†’ ì‹¤ì œ í”„ë ˆì„ ì¸ë±ìŠ¤
#     best_start_sec_global = int(start_idx / fps) + best_start_sec_local
#     best_end_sec_global = best_start_sec_global + window_len

#     # í”„ë ˆì„ ë²”ìœ„ (ë‹«íŒ-ì—´ë¦°)
#     best_start_frame = int(best_start_sec_global * fps)
#     best_end_frame = int(min(end_idx, best_end_sec_global * fps))

#     # ì˜ˆì™¸: 1ì°¨ íŒ¨ìŠ¤ì—ì„œ ë‹¨ í•œ ë²ˆë„ ì‚¬ëŒì´ ì•ˆ ì¡íŒ ê²½ìš° â†’ ê·œì¹™ ê·¸ëŒ€ë¡œ 15ë¶„ êµ¬ê°„ ì‚¬ìš©
#     # (ì¦‰, ì‚¬ëŒ 0ì´ì–´ë„ í•´ë‹¹ êµ¬ê°„ì—ì„œ 2ì´ˆë‹¹ 1í”„ë ˆì„ ì¶”ì¶œ)
#     if best_sum <= 0:
#         # start_idx ê¸°ì¤€ìœ¼ë¡œ ê°€ëŠ¥í•œ ìµœëŒ€ 15ë¶„(ë˜ëŠ” ë‚˜ë¨¸ì§€ ê¸¸ì´) ì‚¬ìš©
#         best_start_frame = start_idx
#         best_end_frame = min(end_idx, start_idx + int(window_len * fps))

#     # ---------------------------
#     # 3) 2ì°¨ íŒ¨ìŠ¤: í•´ë‹¹ êµ¬ê°„ì—ì„œë§Œ 2ì´ˆë‹¹ 1í”„ë ˆì„ ì €ì¥
#     # ---------------------------
#     interval_frames = max(1, int(round(fps * EXTRACT_EVERY_SEC)))
#     saved = 0

#     # 2ì°¨ íŒ¨ìŠ¤ ì§„í–‰ ë°”
#     with tqdm(total=max(0, best_end_frame - best_start_frame),
#               desc=f"[PASS2] {video_filename} [{best_start_frame}-{best_end_frame}) GPU:{device_id}") as pbar:

#         for fidx in range(best_start_frame, best_end_frame, interval_frames):
#             cap.set(cv2.CAP_PROP_POS_FRAMES, fidx)
#             ret, frame = cap.read()
#             if not ret:
#                 break

#             out_name = f"{video_filename}_{fidx:06d}.jpg"
#             out_path = os.path.join(save_dir, out_name)
#             cv2.imwrite(out_path, frame)
#             saved += 1

#             # ì§„í–‰ë°”ëŠ” ì‹¤ì œ ì½ì€ í”„ë ˆì„ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ëµ ì—…ë°ì´íŠ¸
#             pbar.update(interval_frames)

#     cap.release()
#     return saved, save_dir


# # =============================
# # [ì¤‘ìš”] ë©€í‹°í”„ë¡œì„¸ì‹±ìš© Top-level ëŸ¬ë„ˆ (Picklable)
# # =============================
# def runner_top(task_args, video_key, gpu_id):
#     saved, _ = detect_and_extract_worker(task_args)
#     return (video_key, gpu_id, int(saved))


# # =============================
# # GPU ìœ í‹¸: GPU ë¦¬ìŠ¤íŠ¸ íŒŒì‹±
# # =============================
# def parse_gpu_ids() -> list:
#     env = GPU_IDS_ENV.strip()
#     ids = []
#     if env:
#         for tok in env.split(','):
#             tok = tok.strip()
#             if tok and tok.lstrip('-').isdigit():
#                 ids.append(int(tok))

#     if ids:
#         return ids

#     if _YOLO_AVAILABLE and 'torch' in globals() and torch.cuda.is_available():
#         n = torch.cuda.device_count()
#         if n > 0:
#             return list(range(n))

#     return [-1]


# # =============================
# # ì„¸ê·¸ë¨¼íŠ¸ íƒœìŠ¤í¬ ë¹Œë” (ë¹„ë””ì˜¤â†’GPU ê³ ì •, ë‚´ë¶€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘ë ¬)
# # =============================
# def build_segment_tasks_for_video(video_path: str, output_root: str, sub_category: str,
#                                   sampling_rate: int, device_id: int, segments: int):
#     """
#     â€» ì£¼ì˜
#     - 15ë¶„ ìµœì  êµ¬ê°„ì€ ì¼ë°˜ì ìœ¼ë¡œ 'ì „ì²´ ë¹„ë””ì˜¤'ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ë‚˜,
#       ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬ì¡°(ì„¸ê·¸ë¨¼íŠ¸ ë³‘ë ¬)ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•˜ê¸° ìœ„í•´
#       'ê° ì„¸ê·¸ë¨¼íŠ¸ ë‚´ë¶€ì—ì„œ' ìµœì  15ë¶„ì„ ì°¾ê³  ê·¸ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
#     - ì „ì²´ ë¹„ë””ì˜¤ ë‹¨ì¼ íƒœìŠ¤í¬ë¡œ ëŒë ¤ ì „ì—­ ìµœì  15ë¶„ì„ ì°¾ê³  ì‹¶ë‹¤ë©´,
#       segments=1ë¡œ ì„¤ì •í•˜ì„¸ìš”(PERSON_SEGMENTS=1).
#     """
#     cap = cv2.VideoCapture(video_path)
#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     fps = cap.get(cv2.CAP_PROP_FPS) or 0.0
#     cap.release()

#     if total_frames <= 0:
#         return []

#     seg = max(1, int(segments))
#     seg_size = (total_frames + seg - 1) // seg

#     tasks = []
#     for k in range(seg):
#         start_idx = k * seg_size
#         end_idx = min((k + 1) * seg_size, total_frames)
#         if start_idx >= end_idx:
#             break
#         args = (start_idx, end_idx, device_id, video_path, fps, max(1, sampling_rate), output_root, sub_category)
#         tasks.append(args)
#     return tasks


# # =============================
# # ë©”ì¸
# # =============================
# if __name__ == "__main__":
#     t0 = time.time()

#     if INPUT_ROOT is None or OUTPUT_ROOT is None:
#         raise ValueError("INPUT_ROOT / OUTPUT_ROOT í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

#     root_category = Path(INPUT_ROOT).parts[-2] if len(Path(INPUT_ROOT).parts) >= 2 else Path(INPUT_ROOT).name

#     # ì…ë ¥ í´ë” ìŠ¤ìº”
#     all_video_entries = []  # (sub_category, video_file, video_path)
#     for category in os.listdir(INPUT_ROOT):
#         if category in EXCLUDED_CATEGORIES:
#             print(f"âŒ ì œì™¸ëœ í´ë”: {category}")
#             continue
#         category_path = os.path.join(INPUT_ROOT, category)
#         if not os.path.isdir(category_path):
#             continue
#         video_files = [f for f in os.listdir(category_path) if f.lower().endswith((".mp4", ".avi", ".mov", ".mkv"))]
#         for video_file in video_files:
#             video_path = os.path.join(category_path, video_file)
#             all_video_entries.append((category, video_file, video_path))

#     if not all_video_entries:
#         print("ì²˜ë¦¬í•  ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
#         raise SystemExit(0)

#     print(f"ë°œê²¬í•œ ì˜ìƒ ìˆ˜: {len(all_video_entries)}")

#     # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ì‹
#     try:
#         if get_start_method(allow_none=True) != 'spawn':
#             set_start_method('spawn', force=True)
#     except RuntimeError:
#         pass

#     category_frame_counter = defaultdict(int)
#     total_extracted_frames = 0

#     # =====================
#     # ì‚¬ëŒ ê°ì§€ + ê³ ê¸‰ ìŠ¤ì¼€ì¤„ëŸ¬
#     # =====================
#     if PERSON_ONLY:
#         if not _YOLO_AVAILABLE:
#             raise RuntimeError(
#                 "ì‚¬ëŒ ê°ì§€ ëª¨ë“œë¥¼ ì„ íƒí–ˆì§€ë§Œ YOLO/torch ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
#                 "`pip install ultralytics torch` ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
#             )

#         gpu_ids = parse_gpu_ids()  # ì˜ˆ: [0,1]
#         valid_gpu_ids = [g for g in gpu_ids if g >= 0]
#         gpu_count = len(valid_gpu_ids)
#         if gpu_count == 0:
#             print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CPUë¡œ ì§„í–‰í•©ë‹ˆë‹¤. (GPU_IDSê°€ ë¹„ì–´ìˆê±°ë‚˜ GPU ë¯¸íƒì§€)")
#             valid_gpu_ids = [-1]
#             gpu_count = 1

#         print(f"ğŸŸ¢ ì‚¬ìš© GPU: {valid_gpu_ids} | GPUë‹¹ ë™ì‹œ ì²˜ë¦¬ ì œí•œ: {WORKERS_PER_GPU}")

#         # 1) ë¹„ë””ì˜¤ ë¼ìš´ë“œë¡œë¹ˆ ë°°ì • + ì„¸ê·¸ë¨¼íŠ¸ íƒœìŠ¤í¬ ìƒì„±
#         per_gpu_queues = {gid: deque() for gid in valid_gpu_ids}
#         expected_segments = {}
#         done_segments = defaultdict(int)
#         saved_frames_per_video = defaultdict(int)

#         for vidx, (sub_category, video_file, video_path) in enumerate(all_video_entries):
#             if is_processed(PROCESSED_LOG, root_category, sub_category, video_file):
#                 print(f"âœ… ì´ë¯¸ ì²˜ë¦¬ë¨: {video_file}")
#                 continue

#             assigned_gpu = valid_gpu_ids[vidx % gpu_count]
#             print(f"ğŸ¬ ì¤€ë¹„: {video_file} â†’ GPU {assigned_gpu}, ì„¸ê·¸ë¨¼íŠ¸ {PERSON_SEGMENTS}")

#             seg_tasks = build_segment_tasks_for_video(
#                 video_path=video_path,
#                 output_root=OUTPUT_ROOT,
#                 sub_category=sub_category,
#                 sampling_rate=PERSON_SAMPLING_RATE,
#                 device_id=assigned_gpu,
#                 segments=PERSON_SEGMENTS,
#             )
#             if not seg_tasks:
#                 print(f"âš ï¸ {video_file}: ìœ íš¨í•œ í”„ë ˆì„ì´ ì—†ì–´ ìŠ¤í‚µ")
#                 continue

#             video_key = (sub_category, video_file)
#             expected_segments[video_key] = len(seg_tasks)

#             for t in seg_tasks:
#                 per_gpu_queues[assigned_gpu].append((t, video_key, assigned_gpu))

#         total_tasks = sum(len(q) for q in per_gpu_queues.values())
#         if total_tasks == 0:
#             print("ì²˜ë¦¬í•  ì„¸ê·¸ë¨¼íŠ¸ íƒœìŠ¤í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
#             raise SystemExit(0)

#         gpu_semaphores = {gid: threading.BoundedSemaphore(WORKERS_PER_GPU) for gid in valid_gpu_ids}
#         pool_size = max(1, gpu_count * max(1, WORKERS_PER_GPU))
#         print(f"ğŸš€ ì „ì—­ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ â€” í’€ í¬ê¸°: {pool_size} (GPU:{valid_gpu_ids}, GPUë‹¹ ì›Œì»¤:{WORKERS_PER_GPU})")

#         cb_lock = threading.Lock()
#         manager = Manager()
#         remaining = manager.Value('i', total_tasks)

#         def _on_done(result):
#             vkey, gid, saved = result
#             with cb_lock:
#                 done_segments[vkey] += 1
#                 saved_frames_per_video[vkey] += int(saved)
#                 remaining.value -= 1

#                 gpu_semaphores[gid].release()

#                 if done_segments[vkey] == expected_segments[vkey]:
#                     sub_category, video_file = vkey
#                     mark_as_processed(PROCESSED_LOG, root_category, sub_category, video_file)
#                     print(f"âœ… ì™„ë£Œ: {video_file} | ì €ì¥ í”„ë ˆì„: {saved_frames_per_video[vkey]}")

#                 _schedule_more()

#         def _schedule_more():
#             for gid in list(per_gpu_queues.keys()):
#                 while per_gpu_queues[gid] and gpu_semaphores[gid].acquire(blocking=False):
#                     task_args, vkey, g = per_gpu_queues[gid].popleft()
#                     pool.apply_async(runner_top, args=(task_args, vkey, g), callback=_on_done)

#         with Pool(processes=pool_size) as pool:
#             _schedule_more()
#             while True:
#                 with cb_lock:
#                     if remaining.value <= 0:
#                         break
#                 time.sleep(0.1)

#         for (sub_category, video_file), saved_cnt in saved_frames_per_video.items():
#             category_frame_counter[sub_category] += saved_cnt
#             total_extracted_frames += saved_cnt

#     else:
#         # ê¸°ì¡´ ê· ì¼ê°„ê²© ëª¨ë“œ ìœ ì§€
#         def _probe(video_path):
#             cap = cv2.VideoCapture(video_path)
#             fps = cap.get(cv2.CAP_PROP_FPS) or 0.0
#             total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#             duration_sec = int(total_frames / fps) if fps > 0 else 0
#             cap.release()
#             return duration_sec, fps

#         video_tasks = []
#         save_info = []

#         for (sub_category, video_file, video_path) in all_video_entries:
#             if is_processed(PROCESSED_LOG, root_category, sub_category, video_file):
#                 print(f"âœ… ì´ë¯¸ ì²˜ë¦¬ë¨: {video_file}")
#                 continue

#             duration_sec, fps = _probe(video_path)
#             num_frames_to_extract, interval_frames = get_frames_to_extract(duration_sec, fps, frames_per_sec=UNIFORM_FRAMES_PER_SEC)

#             if num_frames_to_extract > 0:
#                 print(f"ğŸ“¹ {video_file} (ê¸¸ì´: {duration_sec}s, FPS: {fps:.2f}) â†’ ì¶”ì¶œ {num_frames_to_extract}ì¥ (ê°„ê²© {interval_frames}í”„ë ˆì„)")
#                 video_name = os.path.splitext(video_file)[0]
#                 save_dir = os.path.join(OUTPUT_ROOT, sub_category, video_name)
#                 video_tasks.append((video_path, save_dir, num_frames_to_extract, interval_frames))
#                 save_info.append((sub_category, video_file))
#             else:
#                 print(f"âš ï¸ {video_file}: ì¶”ì¶œ í”„ë ˆì„ ì—†ìŒ. ìŠ¤í‚µ")

#         print(f"ì´ ì²˜ë¦¬í•  ì˜ìƒ ìˆ˜: {len(video_tasks)}")

#         def process_video_task(task):
#             video_path, save_dir, num_frames, interval_frames = task
#             return save_dir, extract_frames_uniform(video_path, save_dir, num_frames, interval_frames)

#         num_workers = max(1, os.cpu_count() or 4)
#         with Pool(processes=num_workers) as pool:
#             results = pool.map(process_video_task, video_tasks)

#         for idx, (save_dir, frame_count) in enumerate(results):
#             sub_category, video_file = save_info[idx]
#             if frame_count > 0:
#                 category_frame_counter[sub_category] += frame_count
#                 total_extracted_frames += frame_count
#             mark_as_processed(PROCESSED_LOG, root_category, sub_category, video_file)

#     # =====================
#     # ìš”ì•½ ë¡œê·¸ ì €ì¥
#     # =====================
#     now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#     file_exists = os.path.exists(SUMMARY_LOG)

#     print("\nì¶”ì¶œ ìš”ì•½")
#     with open(SUMMARY_LOG, "a", newline="") as f:
#         writer = csv.writer(f)
#         if not file_exists:
#             writer.writerow(["date", "root_category", "sub_category", "image_count"])
#         for cat, count in category_frame_counter.items():
#             print(f" {cat}: {count}ì¥")
#             writer.writerow([now, root_category, cat, count])
#         print(f"ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: {total_extracted_frames}ì¥")
#         writer.writerow([now, root_category, "TOTAL", total_extracted_frames])

#     print("âœ… ëª¨ë“  ì˜ìƒ ì²˜ë¦¬ ë° ë¡œê·¸ ì‘ì„± ì™„ë£Œ")
#     print(f" ì´ ì†Œìš” ì‹œê°„: {time.time() - t0:.1f}ì´ˆ")


#============================================ 
# one segment
#============================================

import os
import cv2
import csv
import time
from pathlib import Path
from collections import defaultdict, deque
from datetime import datetime
from multiprocessing import Pool, get_start_method, set_start_method, Manager
import threading

from tqdm import tqdm
from dotenv import load_dotenv

"""
ê³ ê¸‰ ìŠ¤ì¼€ì¤„ëŸ¬ (ì„¸ë§ˆí¬ì–´ ê¸°ë°˜, Manager.Value ì ìš©)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ìš”êµ¬ì‚¬í•­ ë°˜ì˜:
- YOLOë¡œ ì‚¬ëŒì„ ì°¾ì•„, 'ì‚¬ëŒì´ ê°€ì¥ ë§ì´ íƒì§€ëœ ì—°ì† 15ë¶„' êµ¬ê°„ë§Œ ê³¨ë¼ì„œ
  í•´ë‹¹ êµ¬ê°„ì—ì„œ '2ì´ˆë‹¹ 1í”„ë ˆì„(0.5fps)'ë¡œ ì´ë¯¸ì§€ ì¶”ì¶œ
- ê¸°ì¡´ ë©€í‹°-GPU ìŠ¤ì¼€ì¤„ëŸ¬/ì„¸ë§ˆí¬ì–´/ë¡œê·¸ êµ¬ì¡°ëŠ” ìœ ì§€

êµ¬í˜„ ê°œìš”:
- detect_and_extract_worker:
  1) 1ì°¨ íŒ¨ìŠ¤(ìƒ˜í”Œë§ íƒì§€): sampling_rate ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ì„ í›‘ìœ¼ë©° ì´ˆ ë‹¨ìœ„ë¡œ person ì¹´ìš´íŠ¸ë¥¼ ëˆ„ì 
  2) 15ë¶„(900ì´ˆ) ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ìµœë‹¤ íƒì§€ êµ¬ê°„ ê³„ì‚°
  3) 2ì°¨ íŒ¨ìŠ¤: í•´ë‹¹ êµ¬ê°„ì—ì„œë§Œ 2ì´ˆë‹¹ 1í”„ë ˆì„ìœ¼ë¡œ ì €ì¥
"""

# =============================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.envëŠ” ìƒìœ„ í´ë”ì— ìˆë‹¤ê³  ê°€ì •)
# =============================
env_path = Path(__file__).resolve().parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

# ê³µí†µ ê²½ë¡œ/ì„¤ì •
INPUT_ROOT = os.getenv("INPUT_ROOT")
OUTPUT_ROOT = os.getenv("OUTPUT_ROOT")
ASSIGN_LOG_DIR = os.getenv("ASSIGN_LOG_DIR", ".")
os.makedirs(ASSIGN_LOG_DIR, exist_ok=True)
PROCESSED_LOG = os.path.join(ASSIGN_LOG_DIR, "processed_videos.csv")
SUMMARY_LOG = os.path.join(ASSIGN_LOG_DIR, "frame_summary_log.csv")

# ëª¨ë“œ ì „í™˜
PERSON_ONLY = os.getenv("PERSON_ONLY", "0") in ("1", "true", "True")
UNIFORM_FRAMES_PER_SEC = float(os.getenv("UNIFORM_FRAMES_PER_SEC", "3"))

# ì‚¬ëŒ ê°ì§€(ì„¸ê·¸ë¨¼íŠ¸/ë³‘ë ¬) ì„¤ì •
PERSON_SEGMENTS = int(os.getenv("PERSON_SEGMENTS", "4"))             # [ì£¼ì„ì²˜ë¦¬ ëŒ€ìƒê³¼ ì—°ê´€] ë¹„ë””ì˜¤ë¥¼ Në“±ë¶„
WORKERS_PER_GPU = int(os.getenv("WORKERS_PER_GPU", str(PERSON_SEGMENTS)))  # GPUë‹¹ ë™ì‹œ í”„ë¡œì„¸ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜)
PERSON_SAMPLING_RATE = int(os.getenv("PERSON_SAMPLING_RATE", "5"))    # 1ì°¨ íŒ¨ìŠ¤: ní”„ë ˆì„ë§ˆë‹¤ íƒì§€
YOLO_WEIGHTS = os.getenv("YOLO_WEIGHTS", "yolov8n.pt")
PERSON_CONF = float(os.getenv("PERSON_CONF", "0.25"))

# ë©€í‹°-GPU: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ GPU ID ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: "0,1")
GPU_IDS_ENV = os.getenv("GPU_IDS", "0,1")   # ê¸°ë³¸ê°’: 2ê°œ GPU ìˆë‹¤ê³  ê°€ì •

# ì œì™¸ ì¹´í…Œê³ ë¦¬(ì½¤ë§ˆ êµ¬ë¶„)
EXCLUDED_CATEGORIES = set(
    x.strip() for x in os.getenv("EXCLUDED_CATEGORIES", "").split(",") if x.strip()
)

# [ì‹ ê·œ] 15ë¶„ íƒ€ê²Ÿ êµ¬ê°„(ì´ˆ)
TARGET_WINDOW_SEC = int(os.getenv("TARGET_WINDOW_SEC", str(15 * 60)))
# [ê³ ì •] 2ì´ˆë‹¹ 1í”„ë ˆì„ ì €ì¥
EXTRACT_EVERY_SEC = 2.0

# =============================
# YOLO / torch ì„í¬íŠ¸ (ì‚¬ëŒ ê°ì§€ ëª¨ë“œì—ì„œ ì‚¬ìš©)
# =============================
_YOLO_AVAILABLE = True
try:
    import torch
    from ultralytics import YOLO
except Exception as e:
    _YOLO_AVAILABLE = False
    _YOLO_IMPORT_ERROR = e


# =============================
# ìœ í‹¸ í•¨ìˆ˜ë“¤ (ê· ì¼ê°„ê²© ëª¨ë“œ ìœ ì§€)
# =============================
def get_frames_to_extract(duration_sec, fps, frames_per_sec=3):
    if fps <= 0 or duration_sec <= 0:
        return 0, 0
    num_frames = int(duration_sec * frames_per_sec)
    interval = int(fps / frames_per_sec)
    if interval < 1:
        interval = 1
        num_frames = int(duration_sec * fps)
    return num_frames, interval


def extract_frames_uniform(video_path, save_dir, num_frames, interval_frames):
    cap = cv2.VideoCapture(video_path)
    total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    if num_frames == 0 or total_video_frames < interval_frames:
        print(f"âš ï¸ {os.path.basename(video_path)}: ì¶”ì¶œ í”„ë ˆì„ ì—†ìŒ/ê°„ê²© ê³¼ëŒ€. ìŠ¤í‚µ")
        cap.release()
        return 0

    base_name = os.path.splitext(os.path.basename(video_path))[0]
    os.makedirs(save_dir, exist_ok=True)

    count = 0
    for i in range(num_frames):
        frame_idx = i * interval_frames
        if frame_idx >= total_video_frames:
            break
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            save_path = os.path.join(save_dir, f"{base_name}_frame{i:06d}.jpg")
            cv2.imwrite(save_path, frame)
            count += 1
    cap.release()
    return count


def is_processed(log_file, root_category, sub_category, video_file):
    if not os.path.exists(log_file):
        return False
    with open(log_file, 'r') as f:
        reader = csv.DictReader(f)
        return any(
            row['root_category'] == root_category and
            row['sub_category'] == sub_category and
            row['filename'] == video_file
            for row in reader
        )


def mark_as_processed(log_file, root_category, sub_category, video_file):
    file_exists = os.path.exists(log_file)
    with open(log_file, 'a', newline='') as f:
        fieldnames = ['root_category', 'sub_category', 'filename']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        writer.writerow({
            'root_category': root_category,
            'sub_category': sub_category,
            'filename': video_file
        })


# =============================
# [í•µì‹¬] ì‚¬ëŒ ê°ì§€ìš© ì›Œì»¤ (ì—…ë°ì´íŠ¸ ë²„ì „)
# =============================
def detect_and_extract_worker(args):
    """
    args: (start_idx, end_idx, device_id, video_path, fps, sampling_rate, output_root, category)
    ë™ì‘:
      1) [start_idx, end_idx) ë²”ìœ„ë¥¼ 1ì°¨ íŒ¨ìŠ¤ë¡œ í›‘ìœ¼ë©° PERSON ì¡´ì¬ ì—¬ë¶€ë¥¼ 'ì´ˆ ë‹¨ìœ„' ì¹´ìš´íŠ¸ì— ëˆ„ì 
      2) í•´ë‹¹ ë²”ìœ„ ë‚´ì—ì„œ 'ì—°ì† 15ë¶„(900ì´ˆ)' ìœˆë„ìš° ì¤‘ í•©ê³„ê°€ ìµœëŒ€ì¸ êµ¬ê°„ ì°¾ê¸°
      3) ê·¸ êµ¬ê°„ì—ì„œë§Œ 2ì´ˆë‹¹ 1í”„ë ˆì„ìœ¼ë¡œ ì´ë¯¸ì§€ ì €ì¥
    ë°˜í™˜: (saved_count, save_dir)
    """
    start_idx, end_idx, device_id, video_path, fps, sampling_rate, output_root, category = args

    if not _YOLO_AVAILABLE:
        raise RuntimeError(
            f"ultralytics/torch ì„í¬íŠ¸ ì‹¤íŒ¨: {_YOLO_IMPORT_ERROR}\n"
            f"ì‚¬ëŒ ê°ì§€ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `pip install ultralytics torch`ë¥¼ ë¨¼ì € ì„¤ì¹˜í•˜ì„¸ìš”."
        )

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    use_cuda = False
    if 'torch' in globals():
        use_cuda = torch.cuda.is_available() and device_id is not None and device_id >= 0
        if use_cuda:
            torch.cuda.set_device(device_id)

    # ëª¨ë¸ ë¡œë“œ (ê° í”„ë¡œì„¸ìŠ¤ ë³„ 1íšŒ)
    yolo = YOLO(YOLO_WEIGHTS)

    # ë¹„ë””ì˜¤ ì¤€ë¹„
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = fps or cap.get(cv2.CAP_PROP_FPS) or 0.0

    # ì¶œë ¥ í´ë”
    video_filename = os.path.splitext(os.path.basename(video_path))[0]
    save_dir = os.path.join(output_root, category, video_filename)
    os.makedirs(save_dir, exist_ok=True)

    # ê²½ê³„ ë³´ì •
    start_idx = max(0, start_idx)
    end_idx = min(end_idx, total_frames) if end_idx > 0 else total_frames
    if fps <= 0 or start_idx >= end_idx:
        cap.release()
        return 0, save_dir

    # ---------------------------
    # 1) 1ì°¨ íŒ¨ìŠ¤: ìƒ˜í”Œë§ íƒì§€ â†’ ì´ˆ ë‹¨ìœ„ ì¹´ìš´íŠ¸
    # ---------------------------
    person_count_by_sec = defaultdict(int)

    # 1ì°¨ íŒ¨ìŠ¤ ì§„í–‰ ë°”
    with tqdm(total=(end_idx - start_idx), desc=f"[PASS1] {video_filename} [{start_idx}-{end_idx}) GPU:{device_id}") as pbar:
        frame_idx = start_idx
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_idx)

        while frame_idx < end_idx:
            ret, frame = cap.read()
            if not ret:
                break

            # ìƒ˜í”Œë§ ìŠ¤í‚µ (ì†ë„)
            if sampling_rate > 1 and (frame_idx % sampling_rate != 0):
                frame_idx += 1
                pbar.update(1)
                continue

            # YOLO ì¶”ë¡ 
            results = yolo(frame, verbose=False, conf=PERSON_CONF)[0]
            has_person = False
            if results.boxes is not None and len(results.boxes.cls) > 0:
                for cls_idx in results.boxes.cls.tolist():
                    name = results.names.get(int(cls_idx), "")
                    if name == "person":
                        has_person = True
                        break

            if has_person:
                sec = int(frame_idx / fps)
                person_count_by_sec[sec] += 1

            frame_idx += 1
            pbar.update(1)

    # ---------------------------
    # 2) ìµœì  15ë¶„(900ì´ˆ) ì—°ì† êµ¬ê°„ ê³„ì‚° (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
    # ---------------------------
    total_secs = int((end_idx - start_idx) / fps) + 1
    if total_secs <= 0:
        cap.release()
        return 0, save_dir

    window_len = min(TARGET_WINDOW_SEC, total_secs)  # ì˜ìƒì´ 15ë¶„ë³´ë‹¤ ì§§ìœ¼ë©´ ì˜ìƒ ê¸¸ì´ë¡œ
    # ì´ˆë³„ ì¹´ìš´íŠ¸ë¥¼ ë°°ì—´ë¡œ ë³€í™˜ (start_sec=0 ê¸°ì¤€)
    sec_counts = [0] * total_secs
    for s, c in person_count_by_sec.items():
        local_s = s - int(start_idx / fps)
        if 0 <= local_s < total_secs:
            sec_counts[local_s] += c

    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ìµœëŒ€ í•© ì°¾ê¸° (prefix sum)
    prefix = [0]
    for v in sec_counts:
        prefix.append(prefix[-1] + v)

    best_sum = -1
    best_start_sec_local = 0
    for i in range(0, total_secs - window_len + 1):
        j = i + window_len
        ssum = prefix[j] - prefix[i]
        if ssum > best_sum:
            best_sum = ssum
            best_start_sec_local = i

    # ë¡œì»¬ êµ¬ê°„(ì‹œì‘ì´ˆ) â†’ ì‹¤ì œ í”„ë ˆì„ ì¸ë±ìŠ¤
    best_start_sec_global = int(start_idx / fps) + best_start_sec_local
    best_end_sec_global = best_start_sec_global + window_len

    # í”„ë ˆì„ ë²”ìœ„ (ë‹«íŒ-ì—´ë¦°)
    best_start_frame = int(best_start_sec_global * fps)
    best_end_frame = int(min(end_idx, best_end_sec_global * fps))

    # ì˜ˆì™¸: 1ì°¨ íŒ¨ìŠ¤ì—ì„œ ë‹¨ í•œ ë²ˆë„ ì‚¬ëŒì´ ì•ˆ ì¡íŒ ê²½ìš° â†’ ê·œì¹™ ê·¸ëŒ€ë¡œ 15ë¶„ êµ¬ê°„ ì‚¬ìš©
    if best_sum <= 0:
        best_start_frame = start_idx
        best_end_frame = min(end_idx, start_idx + int(window_len * fps))

    # ---------------------------
    # 3) 2ì°¨ íŒ¨ìŠ¤: í•´ë‹¹ êµ¬ê°„ì—ì„œë§Œ 2ì´ˆë‹¹ 1í”„ë ˆì„ ì €ì¥
    # ---------------------------
    interval_frames = max(1, int(round(fps * EXTRACT_EVERY_SEC)))
    saved = 0

    # 2ì°¨ íŒ¨ìŠ¤ ì§„í–‰ ë°”
    with tqdm(total=max(0, best_end_frame - best_start_frame),
              desc=f"[PASS2] {video_filename} [{best_start_frame}-{best_end_frame}) GPU:{device_id}") as pbar:

        for fidx in range(best_start_frame, best_end_frame, interval_frames):
            cap.set(cv2.CAP_PROP_POS_FRAMES, fidx)
            ret, frame = cap.read()
            if not ret:
                break

            out_name = f"{video_filename}_{fidx:06d}.jpg"
            out_path = os.path.join(save_dir, out_name)
            cv2.imwrite(out_path, frame)
            saved += 1

            # ì§„í–‰ë°”ëŠ” ì‹¤ì œ ì½ì€ í”„ë ˆì„ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ëµ ì—…ë°ì´íŠ¸
            pbar.update(interval_frames)

    cap.release()
    return saved, save_dir


# =============================
# [ì¤‘ìš”] ë©€í‹°í”„ë¡œì„¸ì‹±ìš© Top-level ëŸ¬ë„ˆ (Picklable)
# =============================
def runner_top(task_args, video_key, gpu_id):
    saved, _ = detect_and_extract_worker(task_args)
    return (video_key, gpu_id, int(saved))


# =============================
# GPU ìœ í‹¸: GPU ë¦¬ìŠ¤íŠ¸ íŒŒì‹±
# =============================
def parse_gpu_ids() -> list:
    env = GPU_IDS_ENV.strip()
    ids = []
    if env:
        for tok in env.split(','):
            tok = tok.strip()
            if tok and tok.lstrip('-').isdigit():
                ids.append(int(tok))

    if ids:
        return ids

    if _YOLO_AVAILABLE and 'torch' in globals() and torch.cuda.is_available():
        n = torch.cuda.device_count()
        if n > 0:
            return list(range(n))

    return [-1]


# =============================
# ì„¸ê·¸ë¨¼íŠ¸ íƒœìŠ¤í¬ ë¹Œë” (ë¹„ë””ì˜¤â†’GPU ê³ ì •, ë‚´ë¶€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘ë ¬)
# =============================
# [ì£¼ì„ì²˜ë¦¬] â€” ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì œê±°ë¥¼ ìœ„í•´ í•¨ìˆ˜ ì „ì²´ë¥¼ ë§‰ìŠµë‹ˆë‹¤.
# def build_segment_tasks_for_video(video_path: str, output_root: str, sub_category: str,
#                                   sampling_rate: int, device_id: int, segments: int):
#     """
#     â€» ì£¼ì˜
#     - 15ë¶„ ìµœì  êµ¬ê°„ì€ ì¼ë°˜ì ìœ¼ë¡œ 'ì „ì²´ ë¹„ë””ì˜¤'ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ë‚˜,
#       ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬ì¡°(ì„¸ê·¸ë¨¼íŠ¸ ë³‘ë ¬)ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•˜ê¸° ìœ„í•´
#       'ê° ì„¸ê·¸ë¨¼íŠ¸ ë‚´ë¶€ì—ì„œ' ìµœì  15ë¶„ì„ ì°¾ê³  ê·¸ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
#     - ì „ì²´ ë¹„ë””ì˜¤ ë‹¨ì¼ íƒœìŠ¤í¬ë¡œ ëŒë ¤ ì „ì—­ ìµœì  15ë¶„ì„ ì°¾ê³  ì‹¶ë‹¤ë©´,
#       segments=1ë¡œ ì„¤ì •í•˜ì„¸ìš”(PERSON_SEGMENTS=1).
#     """
#     cap = cv2.VideoCapture(video_path)
#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     fps = cap.get(cv2.CAP_PROP_FPS) or 0.0
#     cap.release()
#
#     if total_frames <= 0:
#         return []
#
#     seg = max(1, int(segments))
#     seg_size = (total_frames + seg - 1) // seg
#
#     tasks = []
#     for k in range(seg):
#         start_idx = k * seg_size
#         end_idx = min((k + 1) * seg_size, total_frames)
#         if start_idx >= end_idx:
#             break
#         args = (start_idx, end_idx, device_id, video_path, fps, max(1, sampling_rate), output_root, sub_category)
#         tasks.append(args)
#     return tasks


# =============================
# ë©”ì¸
# =============================
if __name__ == "__main__":
    t0 = time.time()

    if INPUT_ROOT is None or OUTPUT_ROOT is None:
        raise ValueError("INPUT_ROOT / OUTPUT_ROOT í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

    root_category = Path(INPUT_ROOT).parts[-2] if len(Path(INPUT_ROOT).parts) >= 2 else Path(INPUT_ROOT).name

    # ì…ë ¥ í´ë” ìŠ¤ìº”
    all_video_entries = []  # (sub_category, video_file, video_path)
    for category in os.listdir(INPUT_ROOT):
        if category in EXCLUDED_CATEGORIES:
            print(f"âŒ ì œì™¸ëœ í´ë”: {category}")
            continue
        category_path = os.path.join(INPUT_ROOT, category)
        if not os.path.isdir(category_path):
            continue
        video_files = [f for f in os.listdir(category_path) if f.lower().endswith((".mp4", ".avi", ".mov", ".mkv"))]
        for video_file in video_files:
            video_path = os.path.join(category_path, video_file)
            all_video_entries.append((category, video_file, video_path))

    if not all_video_entries:
        print("ì²˜ë¦¬í•  ë¹„ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        raise SystemExit(0)

    print(f"ë°œê²¬í•œ ì˜ìƒ ìˆ˜: {len(all_video_entries)}")

    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ì‹
    try:
        if get_start_method(allow_none=True) != 'spawn':
            set_start_method('spawn', force=True)
    except RuntimeError:
        pass

    category_frame_counter = defaultdict(int)
    total_extracted_frames = 0

    # =====================
    # ì‚¬ëŒ ê°ì§€ + ê³ ê¸‰ ìŠ¤ì¼€ì¤„ëŸ¬
    # =====================
    if PERSON_ONLY:
        if not _YOLO_AVAILABLE:
            raise RuntimeError(
                "ì‚¬ëŒ ê°ì§€ ëª¨ë“œë¥¼ ì„ íƒí–ˆì§€ë§Œ YOLO/torch ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                "`pip install ultralytics torch` ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
            )

        gpu_ids = parse_gpu_ids()  # ì˜ˆ: [0,1]
        valid_gpu_ids = [g for g in gpu_ids if g >= 0]
        gpu_count = len(valid_gpu_ids)
        if gpu_count == 0:
            print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CPUë¡œ ì§„í–‰í•©ë‹ˆë‹¤. (GPU_IDSê°€ ë¹„ì–´ìˆê±°ë‚˜ GPU ë¯¸íƒì§€)")
            valid_gpu_ids = [-1]
            gpu_count = 1

        print(f"ğŸŸ¢ ì‚¬ìš© GPU: {valid_gpu_ids} | GPUë‹¹ ë™ì‹œ ì²˜ë¦¬ ì œí•œ: {WORKERS_PER_GPU}")

        # 1) ë¹„ë””ì˜¤ ë¼ìš´ë“œë¡œë¹ˆ ë°°ì • + (ì„¸ê·¸ë¨¼íŠ¸ ëŒ€ì‹ ) 'ë‹¨ì¼ íƒœìŠ¤í¬' ìƒì„±
        per_gpu_queues = {gid: deque() for gid in valid_gpu_ids}
        expected_segments = {}
        done_segments = defaultdict(int)
        saved_frames_per_video = defaultdict(int)

        for vidx, (sub_category, video_file, video_path) in enumerate(all_video_entries):
            if is_processed(PROCESSED_LOG, root_category, sub_category, video_file):
                print(f"âœ… ì´ë¯¸ ì²˜ë¦¬ë¨: {video_file}")
                continue

            assigned_gpu = valid_gpu_ids[vidx % gpu_count]

            # [ë³€ê²½] ì„¸ê·¸ë¨¼íŠ¸ ë¬¸êµ¬ ì œê±° + ì „ì—­ 15ë¶„ 1êµ¬ê°„ ì²˜ë¦¬ ì•ˆë‚´
            print(f"ğŸ¬ ì¤€ë¹„: {video_file} â†’ GPU {assigned_gpu} (ì „ì—­ 15ë¶„ 1êµ¬ê°„ ì¶”ì¶œ)")

            # ì „ì²´ ì˜ìƒ ê¸¸ì´/ fps ì¡°íšŒ í›„ 'í•œ ê±´'ì˜ íƒœìŠ¤í¬ë§Œ ìƒì„±
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS) or 0.0
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            cap.release()

            if total_frames <= 0:
                print(f"âš ï¸ {video_file}: ìœ íš¨í•œ í”„ë ˆì„ì´ ì—†ì–´ ìŠ¤í‚µ")
                continue

            task_args = (
                0,                              # start_idx (ì˜ìƒ ì²˜ìŒ)
                total_frames,                   # end_idx   (ì˜ìƒ ë)
                assigned_gpu,                   # device_id
                video_path,                     # video_path
                fps,                            # fps
                max(1, PERSON_SAMPLING_RATE),   # sampling_rate
                OUTPUT_ROOT,                    # output_root
                sub_category                    # category(=í´ë”ëª…)
            )

            video_key = (sub_category, video_file)
            expected_segments[video_key] = 1  # [ë³€ê²½] í•­ìƒ 1ê°œë¡œ ê³ ì •
            per_gpu_queues[assigned_gpu].append((task_args, video_key, assigned_gpu))

        total_tasks = sum(len(q) for q in per_gpu_queues.values())
        if total_tasks == 0:
            print("ì²˜ë¦¬í•  íƒœìŠ¤í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            raise SystemExit(0)

        gpu_semaphores = {gid: threading.BoundedSemaphore(WORKERS_PER_GPU) for gid in valid_gpu_ids}
        pool_size = max(1, gpu_count * max(1, WORKERS_PER_GPU))
        print(f"ğŸš€ ì „ì—­ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ â€” í’€ í¬ê¸°: {pool_size} (GPU:{valid_gpu_ids}, GPUë‹¹ ì›Œì»¤:{WORKERS_PER_GPU})")

        cb_lock = threading.Lock()
        manager = Manager()
        remaining = manager.Value('i', total_tasks)

        def _on_done(result):
            vkey, gid, saved = result
            with cb_lock:
                done_segments[vkey] += 1
                saved_frames_per_video[vkey] += int(saved)
                remaining.value -= 1

                gpu_semaphores[gid].release()

                if done_segments[vkey] == expected_segments[vkey]:
                    sub_category, video_file = vkey
                    mark_as_processed(PROCESSED_LOG, root_category, sub_category, video_file)
                    print(f"âœ… ì™„ë£Œ: {video_file} | ì €ì¥ í”„ë ˆì„: {saved_frames_per_video[vkey]}")

                _schedule_more()

        def _schedule_more():
            for gid in list(per_gpu_queues.keys()):
                while per_gpu_queues[gid] and gpu_semaphores[gid].acquire(blocking=False):
                    task_args, vkey, g = per_gpu_queues[gid].popleft()
                    pool.apply_async(runner_top, args=(task_args, vkey, g), callback=_on_done)

        with Pool(processes=pool_size) as pool:
            _schedule_more()
            while True:
                with cb_lock:
                    if remaining.value <= 0:
                        break
                time.sleep(0.1)

        for (sub_category, video_file), saved_cnt in saved_frames_per_video.items():
            category_frame_counter[sub_category] += saved_cnt
            total_extracted_frames += saved_cnt

    else:
        # ê¸°ì¡´ ê· ì¼ê°„ê²© ëª¨ë“œ ìœ ì§€
        def _probe(video_path):
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS) or 0.0
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration_sec = int(total_frames / fps) if fps > 0 else 0
            cap.release()
            return duration_sec, fps

        video_tasks = []
        save_info = []

        for (sub_category, video_file, video_path) in all_video_entries:
            if is_processed(PROCESSED_LOG, root_category, sub_category, video_file):
                print(f"âœ… ì´ë¯¸ ì²˜ë¦¬ë¨: {video_file}")
                continue

            duration_sec, fps = _probe(video_path)
            num_frames_to_extract, interval_frames = get_frames_to_extract(duration_sec, fps, frames_per_sec=UNIFORM_FRAMES_PER_SEC)

            if num_frames_to_extract > 0:
                print(f"ğŸ“¹ {video_file} (ê¸¸ì´: {duration_sec}s, FPS: {fps:.2f}) â†’ ì¶”ì¶œ {num_frames_to_extract}ì¥ (ê°„ê²© {interval_frames}í”„ë ˆì„)")
                video_name = os.path.splitext(video_file)[0]
                save_dir = os.path.join(OUTPUT_ROOT, sub_category, video_name)
                video_tasks.append((video_path, save_dir, num_frames_to_extract, interval_frames))
                save_info.append((sub_category, video_file))
            else:
                print(f"âš ï¸ {video_file}: ì¶”ì¶œ í”„ë ˆì„ ì—†ìŒ. ìŠ¤í‚µ")

        print(f"ì´ ì²˜ë¦¬í•  ì˜ìƒ ìˆ˜: {len(video_tasks)}")

        def process_video_task(task):
            video_path, save_dir, num_frames, interval_frames = task
            return save_dir, extract_frames_uniform(video_path, save_dir, num_frames, interval_frames)

        num_workers = max(1, os.cpu_count() or 4)
        with Pool(processes=num_workers) as pool:
            results = pool.map(process_video_task, video_tasks)

        for idx, (save_dir, frame_count) in enumerate(results):
            sub_category, video_file = save_info[idx]
            if frame_count > 0:
                category_frame_counter[sub_category] += frame_count
                total_extracted_frames += frame_count
            mark_as_processed(PROCESSED_LOG, root_category, sub_category, video_file)

    # =====================
    # ìš”ì•½ ë¡œê·¸ ì €ì¥
    # =====================
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    file_exists = os.path.exists(SUMMARY_LOG)

    print("\nì¶”ì¶œ ìš”ì•½")
    with open(SUMMARY_LOG, "a", newline="") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["date", "root_category", "sub_category", "image_count"])
        for cat, count in category_frame_counter.items():
            print(f" {cat}: {count}ì¥")
            writer.writerow([now, root_category, cat, count])
        print(f"ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: {total_extracted_frames}ì¥")
        writer.writerow([now, root_category, "TOTAL", total_extracted_frames])

    print("âœ… ëª¨ë“  ì˜ìƒ ì²˜ë¦¬ ë° ë¡œê·¸ ì‘ì„± ì™„ë£Œ")
    print(f" ì´ ì†Œìš” ì‹œê°„: {time.time() - t0:.1f}ì´ˆ")
